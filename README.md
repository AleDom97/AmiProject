# AmiProject
Progetto in cui identificare i contenuti misogini dei tweets.

Il problema preso in considerazione per il progetto riguarda lo svolgimento di
un task appartenente alla challenge di Evalita 2020. Data l’enorme quantità
di contenuti generati dagli utenti sul Web, e in particolare sui social media,
il problema di individuare e quindi limitare la diffusione del discorso di odio
contro le donne sta rapidamente diventando fondamentale soprattutto per
l’impatto sociale del fenomeno. L’attività AMI ha quindi lo scopo di identificare automaticamente i contenuti misogini di Twitter in italiano e quindi si
tratta di un problema di apprendimento supervisionato di tipo NLP (Natural
Language Processing).
Diamo adesso una breve definizione di misogino e di aggressivo, il primo
viene preso in considerazione se una frase contiene parole che screditano le
donne in qualsiasi modo o approccio. Diversi esempi di questo odio contro
le donne vengono manifestati attraverso l’esclusione sociale, la discriminazione sessuale, l’ostilità e l’oggettificazione. Mentre per quanto riguarda la
definizione di aggressivo questa viene strettamente legata alla presenza di
misoginia, dunque solo in caso di essa potrà esserci un comportamento aggressivo o meno. Si ha un comportamento aggressivo quando si usano parole
particolarmente offensive verso un determinato individuo.
